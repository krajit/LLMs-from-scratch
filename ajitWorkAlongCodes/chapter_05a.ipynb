{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.1\n",
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
       "          5308,  3398, 13174, 43071]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you rentingetic wasnم refres RexMeCHicular stren'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(token_ids,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],\n",
    "                       [40, 1107, 588]])\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],\n",
    "                        [1107, 588, 11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[16657],\n",
       "         [  339],\n",
       "         [42826]],\n",
       "\n",
       "        [[49906],\n",
       "         [29669],\n",
       "         [41751]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' pressuring empoweredfaith'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(token_ids[1].flatten(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx,[0,1,2],targets[text_idx]]\n",
    "print(target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx,[0,1,2],targets[text_idx]]\n",
    "print(target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3626, 6100,  345])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.7940)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "avg_log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "logits_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_flat = targets.flatten()\n",
    "targets_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3626,  6100,   345,  1107,   588, 11311])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1113, -0.1057, -0.3666,  ...,  0.2843, -0.8824,  0.1074],\n",
       "        [-0.6109, -0.5167, -0.7613,  ...,  0.5450, -1.0319, -0.2175],\n",
       "        [ 0.5707, -0.6459, -0.0701,  ...,  0.7419, -0.1806, -0.2217],\n",
       "        [-0.2968,  0.1949, -0.1649,  ..., -0.4867,  0.7218, -0.1714],\n",
       "        [-0.8375,  0.0612, -0.4641,  ...,  0.2327, -0.3889, -0.0770],\n",
       "        [ 0.5614,  0.6919,  0.8915,  ..., -0.9472,  1.2411, -0.2056]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7940)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48725.8203)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perplexity\n",
    "perplexity = torch.exp(loss)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio*len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6b98725210>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride = GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "        batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride = GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "for x,y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583372328016\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "                train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "            )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                        optimizer, device, num_epochs,\n",
    "                        eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "            input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "  \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                        model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                f\"Train loss {train_loss:.3f}, \"\n",
    "                f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        generate_and_print_sample(\n",
    "       model, tokenizer, device, start_context\n",
    "    )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 8.050, Val loss 8.333\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.758, Val loss 7.046\n",
      "Ep 2 (Step 000015): Train loss 6.142, Val loss 6.630\n",
      "Every effort moves you, and, and, and, and, and, and, and.                                   \n",
      "Ep 3 (Step 000020): Train loss 13.925, Val loss 14.195\n",
      "Ep 3 (Step 000025): Train loss 5.513, Val loss 6.420\n",
      "Every effort moves you, and to the\"                                             \n",
      "Ep 4 (Step 000030): Train loss 5.165, Val loss 6.381\n",
      "Ep 4 (Step 000035): Train loss 4.753, Val loss 6.316\n",
      "Every effort moves you.                           \"I\"I\"I\"I it's\"I\"I\"I\"I\"I\"I\n",
      "Ep 5 (Step 000040): Train loss 4.627, Val loss 6.394\n",
      "Every effort moves you, I had been.                       \"II me, and he had the donkey.           \n",
      "Ep 6 (Step 000045): Train loss 4.026, Val loss 6.260\n",
      "Ep 6 (Step 000050): Train loss 3.541, Val loss 6.210\n",
      "Every effort moves you know the                          \"Oh, and the end the end the end the fact the end the picture--as.   \n",
      "Ep 7 (Step 000055): Train loss 3.182, Val loss 6.110\n",
      "Ep 7 (Step 000060): Train loss 2.504, Val loss 6.097\n",
      "Every effort moves you know the                                  \"Oh, I said a little a little the room, I was\n",
      "Ep 8 (Step 000065): Train loss 2.254, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 1.922, Val loss 6.193\n",
      "Every effort moves you know,\" was not that my dear--I had the fact with a laugh: \"Yes--and by me to me, the cigars you like.\"      \"--and it, the donkey. \"There were, I had\n",
      "Ep 9 (Step 000075): Train loss 1.572, Val loss 6.231\n",
      "Ep 9 (Step 000080): Train loss 1.252, Val loss 6.239\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as--the him.   \"--that I was\n",
      "Ep 10 (Step 000085): Train loss 0.885, Val loss 6.284\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs. \"Oh, my work, and went on groping and muddling; then I looked at the donkey again. I saw that, when Stroud laid in the first\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAEiCAYAAADkhpu7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYDlJREFUeJzt3Xd4VFX6wPHvzKSXmRRSSaGFQEISOlKsIKGIggouyyqK4k8FlWWtqyBWLIjYFtsK61oQdUFEioAISm8JobeQQhqQ3suc3x+TTBgISEKSSYb38zz3ydxzz733nUvCe8u552iUUgohhBBC2AyttQMQQgghROOS5C6EEELYGEnuQgghhI2R5C6EEELYGEnuQgghhI2R5C6EEELYGEnuQgghhI2R5C6EEELYGEnuQgghhI2R5C7EVerkyZNoNBri4uKsHYoQopFJcheiFdNoNJecZs2aZe0QhRBWYGftAIQQDZeenm7+/O233zJz5kwOHz5sLnNzc7NGWEIIK5MrdyFaMX9/f/NkMBjQaDTmeV9fX+bOnUtQUBCOjo50796dVatWXXRbVVVVTJo0iS5dupCcnAzAjz/+SM+ePXFycqJDhw68+OKLVFZWmtfRaDR89tlnjBkzBhcXF8LCwli2bJl5eU5ODhMmTMDHxwdnZ2fCwsJYsGDBRWP4/vvviYqKwtnZGW9vb4YMGUJRUZF5+WeffUbXrl1xcnKiS5cu/Otf/7JYPyUlhXHjxuHh4YGXlxe33XYbJ0+eNC+/9957GT16NHPmzCEgIABvb2+mTJlCRUXFZR9zIVoFJYSwCQsWLFAGg8E8P3fuXKXX69U333yjDh06pJ566illb2+vjhw5opRSKjExUQFqz549qrS0VI0ZM0b16NFDZWVlKaWU2rhxo9Lr9WrhwoXq+PHj6pdfflHt2rVTs2bNMu8DUEFBQerrr79WR48eVY899phyc3NTZ8+eVUopNWXKFNW9e3e1Y8cOlZiYqNasWaOWLVtWZ/xpaWnKzs5OzZ07VyUmJqq9e/eqDz/8UBUUFCillPryyy9VQECA+uGHH9SJEyfUDz/8oLy8vNTChQuVUkqVl5errl27qkmTJqm9e/eqAwcOqL/+9a8qPDxclZWVKaWUmjhxotLr9eqhhx5SBw8eVD/99JNycXFRn3zySeP+YwhhZZLchbAR5yf3wMBA9eqrr1rU6dOnj3rkkUeUUrXJ/ffff1eDBw9WgwYNUrm5uea6gwcPVq+99prF+v/9739VQECAeR5Qzz//vHm+sLBQAWrlypVKKaVGjRql7rvvvsuKf9euXQpQJ0+erHN5x44d1ddff21R9vLLL6v+/fubYwsPD1dGo9G8vKysTDk7O6vVq1crpUzJPTQ0VFVWVprrjB07Vt11112XFaMQrYU8cxfCBuXn55OWlsbAgQMtygcOHEh8fLxF2fjx4wkKCuLXX3/F2dnZXB4fH8+mTZt49dVXzWVVVVWUlpZSXFyMi4sLANHR0eblrq6u6PV6srKyAHj44Ye544472L17N0OHDmX06NEMGDCgzphjYmIYPHgwUVFRxMbGMnToUO688048PT0pKiri+PHj3H///UyePNm8TmVlJQaDwRzvsWPHcHd3t9huaWkpx48fN89HRkai0+nM8wEBASQkJFziaArR+khyF+IqN2LECL788ku2bNnCTTfdZC4vLCzkxRdf5Pbbb79gHScnJ/Nne3t7i2UajQaj0QjA8OHDSUpKYsWKFaxZs4bBgwczZcoU5syZc8E2dToda9asYfPmzfzyyy+8//77PPfcc2zbts18IvHpp5/Sr1+/C9aribdXr1589dVXF2zbx8fnsuIVwlZIchfCBun1egIDA9m0aRPXX3+9uXzTpk307dvXou7DDz9Mt27duPXWW/n555/N9Xv27Mnhw4fp1KnTFcXi4+PDxIkTmThxItdeey1PPvlknckdTIl24MCBDBw4kJkzZxIaGsqSJUuYPn06gYGBnDhxggkTJtS5bs+ePfn222/x9fVFr9dfUcxCtHaS3IWwUU8++SQvvPACHTt2pHv37ixYsIC4uLg6r2wfffRRqqqquOWWW1i5ciWDBg1i5syZ3HLLLYSEhHDnnXei1WqJj49n3759vPLKK5cVw8yZM+nVqxeRkZGUlZWxfPlyunbtWmfdbdu2sW7dOoYOHYqvry/btm3j9OnT5vovvvgijz32GAaDgWHDhlFWVsbOnTvJyclh+vTpTJgwgbfeeovbbruNl156iaCgIJKSkvjf//7HU089RVBQUMMPphCtjCR3IWzUY489Rl5eHv/4xz/IysoiIiKCZcuWERYWVmf9adOmYTQaGTFiBKtWrSI2Npbly5fz0ksv8cYbb2Bvb0+XLl144IEHLjsGBwcHnn32WU6ePImzszPXXnstixYtqrOuXq9n48aNzJs3j/z8fEJDQ3n77bcZPnw4AA888AAuLi689dZbPPnkk7i6uhIVFcW0adMAcHFxYePGjTz99NPcfvvtFBQU0LZtWwYPHixX8uKqo1FKKWsHIYQQQojGI53YCCGEEDZGkrsQQghhYyS5CyGEEDZGkrsQQghhYyS5CyGEEDZGkrsQQghhYyS5N6IPP/yQdu3a4eTkRL9+/di+fbu1Q2oRNm7cyKhRowgMDESj0bB06VKL5UopZs6cSUBAAM7OzgwZMoSjR49a1MnOzmbChAno9Xo8PDy4//77KSwstKizd+9err32WpycnAgODubNN9+8IJbvvvuOLl264OTkRFRUFCtWrGj079vcZs+eTZ8+fXB3d8fX15fRo0dbjOkOpv7Vp0yZgre3N25ubtxxxx1kZmZa1ElOTmbkyJG4uLjg6+vLk08+aTG8K8Bvv/1Gz549cXR0pFOnTixcuPCCeGzt72D+/PlER0ej1+vR6/X079+flStXmpfLsW1cr7/+OhqNxtx/AcgxbhArD1xjMxYtWqQcHBzU559/rvbv368mT56sPDw8VGZmprVDs7oVK1ao5557Tv3vf/9TgFqyZInF8tdff10ZDAa1dOlSFR8fr2699VbVvn17VVJSYq4zbNgwFRMTo7Zu3ap+//131alTJzV+/Hjz8ry8POXn56cmTJig9u3bp7755hvl7OysPv74Y3OdTZs2KZ1Op95880114MAB9fzzzyt7e3uVkJDQ5MegKcXGxqoFCxaoffv2qbi4ODVixAgVEhKiCgsLzXUeeughFRwcrNatW6d27typrrnmGjVgwADz8srKStWtWzc1ZMgQtWfPHrVixQrVpk0b9eyzz5rrnDhxQrm4uKjp06erAwcOqPfff1/pdDq1atUqcx1b/DtYtmyZ+vnnn9WRI0fU4cOH1T//+U9lb2+v9u3bp5SSY9uYtm/frtq1a6eio6PV448/bi6XY1x/ktwbSd++fdWUKVPM81VVVSowMFDNnj3bilG1POcnd6PRqPz9/dVbb71lLsvNzVWOjo7qm2++UUopdeDAAQWoHTt2mOusXLlSaTQaderUKaWUUv/617+Up6enedxupZR6+umnVXh4uHl+3LhxauTIkRbx9OvXT/3f//1fo35Ha8vKylKA2rBhg1LKdDzt7e3Vd999Z65z8OBBBagtW7YopUwnYFqtVmVkZJjrzJ8/X+n1evMxfeqpp1RkZKTFvu666y4VGxtrnr9a/g48PT3VZ599Jse2ERUUFKiwsDC1Zs0adf3115uTuxzjhpHb8o2gvLycXbt2MWTIEHOZVqtlyJAhbNmyxYqRtXyJiYlkZGRYHDuDwUC/fv3Mx27Lli14eHjQu3dvc50hQ4ag1WrZtm2buc51112Hg4ODuU5sbCyHDx8mJyfHXOfc/dTUsbV/o7y8PAC8vLwA2LVrFxUVFRbfvUuXLoSEhFgc46ioKPz8/Mx1YmNjyc/PZ//+/eY6lzp+V8PfQVVVFYsWLaKoqIj+/fvLsW1EU6ZMYeTIkRccBznGDSN9yzeCM2fOUFVVZfGLBeDn58ehQ4esFFXrkJGRAVDnsatZlpGRga+vr8VyOzs7vLy8LOq0b9/+gm3ULPP09CQjI+OS+7EFRqORadOmMXDgQLp16waYvr+DgwMeHh4Wdc8/xnUdm5pll6qTn59PSUkJOTk5Nvt3kJCQQP/+/SktLcXNzY0lS5YQERFBXFycHNtGsGjRInbv3s2OHTsuWCa/vw0jyV0IGzJlyhT27dvHH3/8Ye1QbEp4eDhxcXHk5eXx/fffM3HiRDZs2GDtsGxCSkoKjz/+OGvWrMHJycna4dgMuS3fCNq0aYNOp7ug9WZmZib+/v5Wiqp1qDk+lzp2/v7+ZGVlWSyvrKwkOzvbok5d2zh3HxerYyv/RlOnTmX58uWsX7/eYnhTf39/ysvLyc3Ntah//jFu6PHT6/U4Ozvb9N+Bg4MDnTp1olevXsyePZuYmBjeffddObaNYNeuXWRlZdGzZ0/s7Oyws7Njw4YNvPfee9jZ2eHn5yfHuAEkuTcCBwcHevXqxbp168xlRqORdevW0b9/fytG1vK1b98ef39/i2OXn5/Ptm3bzMeuf//+5ObmsmvXLnOdX3/9FaPRSL9+/cx1Nm7cSEVFhbnOmjVrCA8Px9PT01zn3P3U1Gnt/0ZKKaZOncqSJUv49ddfL3g80atXL+zt7S2+++HDh0lOTrY4xgkJCRYnUWvWrEGv1xMREWGuc6njdzX9HRiNRsrKyuTYNoLBgweTkJBAXFyceerduzcTJkwwf5Zj3ADWbtFnKxYtWqQcHR3VwoUL1YEDB9SDDz6oPDw8LFpvXq0KCgrUnj171J49exSg5s6dq/bs2aOSkpKUUqZX4Tw8PNSPP/6o9u7dq2677bY6X4Xr0aOH2rZtm/rjjz9UWFiYxatwubm5ys/PT919991q3759atGiRcrFxeWCV+Hs7OzUnDlz1MGDB9ULL7xgE6/CPfzww8pgMKjffvtNpaenm6fi4mJznYceekiFhISoX3/9Ve3cuVP1799f9e/f37y85lWioUOHqri4OLVq1Srl4+NT56tETz75pDp48KD68MMP63yVyNb+Dp555hm1YcMGlZiYqPbu3aueeeYZpdFo1C+//KKUkmPbFM5tLa+UHOOGkOTeiN5//30VEhKiHBwcVN++fdXWrVutHVKLsH79egVcME2cOFEpZXodbsaMGcrPz085OjqqwYMHq8OHD1ts4+zZs2r8+PHKzc1N6fV6dd9996mCggKLOvHx8WrQoEHK0dFRtW3bVr3++usXxLJ48WLVuXNn5eDgoCIjI9XPP//cZN+7udR1bAG1YMECc52SkhL1yCOPKE9PT+Xi4qLGjBmj0tPTLbZz8uRJNXz4cOXs7KzatGmj/vGPf6iKigqLOuvXr1fdu3dXDg4OqkOHDhb7qGFrfweTJk1SoaGhysHBQfn4+KjBgwebE7tScmybwvnJXY5x/WmUUso69wyEEEII0RTkmbsQQghhYyS5CyGEEDZGkrsQQghhYyS5CyGEEDZGkrsQQghhYyS5CyGEEDZGknsjKysrY9asWZSVlVk7FJskx7dpyfFtenKMm5YcXxN5z72R5efnYzAYyMvLQ6/XWzscmyPHt2nJ8W16coyblhxfE7lyF0IIIWyMJHchhBDCxsh47nWorKxkz549+Pn5odXW7/ynoKAAgFOnTpGfn98U4V3V5Pg2LTm+TU+OcdOy5eNrNBrJzMykR48e2NldOn3LM/c67Nixg759+1o7DCGEEOIC27dvp0+fPpesI1fudfDz8wNMBzAgIMDK0QghhBCQnp5O3759zTnqUiS516HmVnxAQABBQUFWjkYIIYSodTmPi6VBnRBCCGFjJLkLIYQQNkaSuxBCCGFj5Jm7EEJcoaqqKioqKqwdhmjl7O3t0el0jbItSe7Cdpw9Dq4+4HT1djkpmpdSioyMDHJzc60dirARHh4e+Pv7o9Formg7ktyFbUjbA5/cAGGxMGGxtaMRV4maxO7r64uLi8sV/4csrl5KKYqLi8nKygK44tewJbkL27DtY9PPo6uhohTsnawbj7B5VVVV5sTu7e1t7XCEDXB2dgYgKysLX1/fK7pFLw3qhG0oyKj9nB5ntTDE1aPmGbuLi4uVIxG2pOb36UrbcEhyF61fVSUqdXvtfMo268UirjpyK140psb6fZLkLlo/YwV7Oj1WO58syV0IcXWT5C5aP3tnvtWO4PayWQBUJW8FGQ9JiGbVrl075s2bd9n1f/vtNzQaTZO/abBw4UI8PDyadB8tkSR3YRN2JmWzT7WnTNmhKzkL2SesHZIQLZJGo7nkNGvWrAZtd8eOHTz44IOXXX/AgAGkp6djMBgatD9xadJaXrRuSlG0/UvUmVLKCSBBdaC35ojpubt3R2tHJ0SLk56ebv787bffMnPmTA4fPmwuc3NzM39WSlFVVfWnY4cD+Pj41CsOBwcH/P3967WOuHxy5S5at9wkXFdOZZXD0zhSwU5jZ1N58lbrxiVEC+Xv72+eDAYDGo3GPH/o0CHc3d1ZuXIlvXr1wtHRkT/++IPjx49z22234efnh5ubG3369GHt2rUW2z3/trxGo+Gzzz5jzJgxuLi4EBYWxrJly8zLz78tX3P7fPXq1XTt2hU3NzeGDRtmcTJSWVnJY489hoeHB97e3jz99NNMnDiR0aNH1+sYzJ8/n44dO+Lg4EB4eDj//e9/zcuUUsyaNYuQkBAcHR0JDAzkscdq2/T861//IiwsDCcnJ/z8/Ljzzjvrte/mIsldtG6l+aS492CnMZzObX3YbQwDQBVmWTkwcTVSSlFcXmmVSTViO5NnnnmG119/nYMHDxIdHU1hYSEjRoxg3bp17Nmzh2HDhjFq1CiSk5MvuZ0XX3yRcePGsXfvXkaMGMGECRPIzs6+aP3i4mLmzJnDf//7XzZu3EhycjJPPPGEefkbb7zBV199xYIFC9i0aRP5+fksXbq0Xt9tyZIlPP744/zjH/9g3759/N///R/33Xcf69evB+CHH37gnXfe4eOPP+bo0aMsXbqUqKgoAHbu3Mljjz3GSy+9xOHDh1m1ahXXXXddvfbfXOS2vGjdAqL5h9tstp8+y6t9g3lreU+6l37M90NG0snasYmrTklFFREzV1tl3wdeisXFoXH+S3/ppZe4+eabzfNeXl7ExMSY519++WWWLFnCsmXLmDp16kW3c++99zJ+/HgAXnvtNd577z22b9/OsGHD6qxfUVHBRx99RMeOpkdqU6dO5aWXXjIvf//993n22WcZM2YMAB988AErVqyo13ebM2cO9957L4888ggA06dPZ+vWrcyZM4cbb7yR5ORk/P39GTJkCPb29oSEhNC3b18AkpOTcXV15ZZbbsHd3Z3Q0FB69OhRr/03F7lyF61aRZWR+JRcQEO/9l50butDLu7EpeRZOzQhWq3evXtbzBcWFvLEE0/QtWtXPDw8cHNz4+DBg3965R4dHW3+7Orqil6vN3evWhcXFxdzYgdTF6w19fPy8sjMzDQnWgCdTkevXr3q9d0OHjzIwIEDLcoGDhzIwYMHARg7diwlJSV06NCByZMns2TJEiorKwG4+eabCQ0NpUOHDtx999189dVXFBcX12v/zUWu3EXrVVHC4aQsyiqNeLjY06GNGzHBBrafzCY+JZc7ewVZO0JxlXG213HgpVir7buxuLq6Wsw/8cQTrFmzhjlz5tCpUyecnZ258847KS8vv+R27O3tLeY1Gg1Go7Fe9RvzccPlCA4O5vDhw6xdu5Y1a9bwyCOP8NZbb7Fhwwbc3d3ZvXs3v/32G7/88gszZ85k1qxZ7Nixo8W9bidX7qL1Or6ebl9G87H9XHqGeKLVaogJ9iBKc4Kx+x+Cr++ydoTiKqPRaHBxsLPK1JQ95W3atIl7772XMWPGEBUVhb+/PydPnmyy/dXFYDDg5+fHjh07zGVVVVXs3r27Xtvp2rUrmzZtsijbtGkTERER5nlnZ2dGjRrFe++9x2+//caWLVtISEgAwM7OjiFDhvDmm2+yd+9eTp48ya+//noF36xpyJW7aL2StwBwVrnTK9QTgJggD0pxILoiAZV4HE1VBejsL7UVIcSfCAsL43//+x+jRo1Co9EwY8aMS16BN5VHH32U2bNn06lTJ7p06cL7779PTk5OvU5snnzyScaNG0ePHj0YMmQIP/30E//73//Mrf8XLlxIVVUV/fr1w8XFhS+//BJnZ2dCQ0NZvnw5J06c4LrrrsPT05MVK1ZgNBoJDw9vqq/cYHLlLlotVf26205juDm5B3k6k+PcjqcrJnPolqWglfNXIa7U3Llz8fT0ZMCAAYwaNYrY2Fh69uzZ7HE8/fTTjB8/nnvuuYf+/fvj5uZGbGwsTk6XPwrk6NGjeffdd5kzZw6RkZF8/PHHLFiwgBtuuAEwjaf+6aefMnDgQKKjo1m7di0//fQT3t7eeHh48L///Y+bbrqJrl278tFHH/HNN98QGRnZRN+44TSquR9otAKpqakEBweTkpJCUJA8t22RKkpQs4PRGCu4ofxdVs66G2cH0zPHSQt38OuhLGaNiuDege2tHKiwVaWlpSQmJtK+fft6JRfReIxGI127dmXcuHG8/PLL1g6nUVzq96o+uUmu3EXrdGo3GmMFGcoTQ0BHc2IH0615gPhUaTEvhC1JSkri008/5ciRIyQkJPDwww+TmJjIX//6V2uH1uJYNblv3LiRUaNGERgYiEajseiMoKKigqeffpqoqChcXV0JDAzknnvuIS0t7ZLbnDVr1gV9JXfp0qWJv4lodtXP23caw+nZzstiUUywAVdKaHf8K/j5H9aITgjRBLRaLQsXLqRPnz4MHDiQhIQE1q5dS9euXa0dWotj1QeSRUVFxMTEMGnSJG6//XaLZcXFxezevZsZM2YQExNDTk4Ojz/+OLfeeis7d+685HYjIyMtuka8nH6RRStTndx3GMPpG3pecg/ywIiGKWWfwQ4jDPo7GOTxihCtXXBw8AUt3UXdrJr1hg8fzvDhw+tcZjAYWLNmjUXZBx98QN++fUlOTiYkJOSi27Wzs5MBCWyZsQqVsg0Npiv3h6sb09XwdHXA19uLAwWhRGsSTYPISHIXQlxFWtUz97y8PDQazZ92FnD06FECAwPp0KEDEyZM+NNelMrKysjPzzdPBQUFjRi1aHRZB9CUFVCgnCnQd8bfcGFjppggD3aZB5HZ1swBCiGEdbWa5F5aWmp+DUKv11+0Xr9+/Vi4cCGrVq1i/vz5JCYmcu21114yYc+ePRuDwWCezu3MQLRA1a/A7TF2onu7NnVWiQk+J7mnSHIXQlxdWkVyr6ioYNy4cSilmD9//iXrDh8+nLFjxxIdHU1sbCwrVqwgNzeXxYsXX3SdZ599lry8PPN04MCBxv4KojGd87y9dzvPOqt0D/YwD/+qMhKgrLDZwhNCCGtr8cm9JrEnJSWxZs2aS16118XDw4POnTtz7Nixi9ZxdHREr9ebJ3d39ysNWzQVpVBJ1S3lVTg9Q+pO7pGBes5o23BKeaNRVZBWvy4qhRCiNWvRyb0msR89epS1a9fi7e1d720UFhZy/PhxAgICmiBC0eyKszGWF1GhdByx60wX/7pPxJzsdXQJcJfn7kKIq5JVk3thYSFxcXHExcUBkJiYSFxcHMnJyVRUVHDnnXeyc+dOvvrqK6qqqsjIyCAjI8NiJKLBgwfzwQcfmOefeOIJNmzYwMmTJ9m8eTNjxoxBp9OZxxQWrZyrN9/csIHB5XPoEuKPne7iv8IWjerkubsQjeqGG25g2rRp5vl27doxb968S65zfn8mDdVY27mUWbNm0b179ybdR1OyanLfuXMnPXr0MA92P336dHr06MHMmTM5deoUy5YtIzU1le7duxMQEGCeNm/ebN7G8ePHOXPmjHk+NTWV8ePHEx4ezrhx4/D29mbr1q34+Pg0+/cTTWN3ch7Jyo9eF7klXyPmnOfupG4HKwx0IURLM2rUKIYNG1bnst9//x2NRsPevXvrvd0dO3bw4IMPXml4Fi6WYNPT0y/6GrUwsep77jfccMMlx+q9nG7vzx92cNGiRVcalmjhdiXnANDrvJ7pztc92INnVQjFyhGX0jw4cxh8pScrcXW7//77ueOOO0hNTb2gf/IFCxbQu3dvoqOj673d5ryAkn5M/lyLfuYuhIXibKrmRjEt/y3sNFX0CPG4ZPWOPm44OTiwx9jJVFD9Cp0QV7NbbrkFHx8fFi5caFFeWFjId999x/3338/Zs2cZP348bdu2xcXFhaioKL755ptLbvf82/JHjx7luuuuw8nJiYiIiAs6JQPTKG+dO3fGxcWFDh06MGPGDCoqKgDT0Ksvvvgi8fHx5q7Ea2I+/7Z8QkICN910E87Oznh7e/Pggw9SWFj7hsy9997L6NGjmTNnDgEBAXh7ezNlyhTzvi6H0WjkpZdeIigoCEdHR7p3786qVavMy8vLy5k6dSoBAQE4OTkRGhrK7NmzAdOF6qxZswgJCcHR0ZHAwEAee+yxy953Q0i/rKL1SNmOLj+ZaE0Fnfw80Dtdepx2nVZDVJCBXclhDGQ/pGyH3vc1U7DiqlZeVP91dI6gq/4vuaoSqspAowV75z/froPrZe/Gzs6Oe+65h4ULF/Lcc8+Zx0L/7rvvqKqqYvz48RQWFtKrVy+efvpp9Ho9P//8M3fffTcdO3akb9++f7oPo9HI7bffjp+fH9u2bSMvL8/i+XwNd3d3Fi5cSGBgIAkJCUyePBl3d3eeeuop7rrrLvbt28eqVavM3YkbDIYLtlFUVERsbCz9+/dnx44dZGVl8cADDzB16lSLE5j169cTEBDA+vXrOXbsGHfddRfdu3dn8uTJl3Xc3n33Xd5++20+/vhjevToweeff86tt97K/v37CQsL47333mPZsmUsXryYkJAQUlJSSElJAeCHH37gnXfeYdGiRURGRpKRkUF8fPxl7behJLmL1qP9tXwV/h6/JZykZ+iln7fXiAn24LfE7vTx09I/cnTTxidEjdcC67/O2IUQOcb0+dBP8N29EDoI7vu5ts68KCg+e+G6s+o3AuKkSZN466232LBhg3kc8wULFnDHHXeYO/N64oknzPUfffRRVq9ezeLFiy8rua9du5ZDhw6xevVqAgNNx+K111674Dn5888/b/7crl07nnjiCRYtWsRTTz2Fs7Mzbm5uf9qd+Ndff01paSlffPEFrq6mk5wPPviAUaNG8cYbb+Dn5weAp6cnH3zwATqdji5dujBy5EjWrVt32cl9zpw5PP300/zlL38B4I033mD9+vXMmzePDz/8kOTkZMLCwhg0aBAajYbQ0FDzusnJyfj7+zNkyBDs7e0JCQm5rON4JeS2vGg9HFz5IacTa4y9/7QxXY3uQR7sVp15RU2CzrFNHKAQrUOXLl0YMGAAn3/+OQDHjh3j999/5/777wegqqqKl19+maioKLy8vHBzc2P16tV/2pV3jYMHDxIcHGxO7AD9+/e/oN63337LwIED8ff3x83Njeeff/6y93HuvmJiYsyJHWDgwIEYjUYOHz5sLouMjESnqx0aOiAggKysrMvaR35+PmlpaQwcONCifODAgRw8eBAw3fqPi4sjPDycxx57jF9++cVcb+zYsZSUlNChQwcmT57MkiVLqKysrNf3rC+5chetRmlFFftO5QNctGe688UEewBwKKOA0ooqnOx1l15BiMbwz0sPTV0nnWPt5y6jTNvQnHf9NS3hyuI6x/3338+jjz7Khx9+yIIFC+jYsSPXX389AG+99Rbvvvsu8+bNMw+7PW3aNIvXkK/Uli1bmDBhAi+++CKxsbEYDAYWLVrE22+/3Wj7OJe9veVjPI1Gg7ER36Dp2bMniYmJrFy5krVr1zJu3DiGDBnC999/T3BwMIcPH2bt2rWsWbOGRx55xHzn5Py4GotcuYvWIT2e3KVP0U/F0cbNgRAvl8taLcDghI+7I3bGMk7uXguJvzdxoEJgegZe30l3zrWWzs5Udu7z9ktttwHGjRuHVqvl66+/5osvvmDSpEnm5++bNm3itttu429/+xsxMTF06NCBI0eOXPa2u3btSkpKCunp6eayrVstG7Ru3ryZ0NBQnnvuOXr37k1YWBhJSUmWX9fBgaqqqj/dV3x8PEVFte0RNm3ahFarJTw8/LJjvhS9Xk9gYOAFw81u2rTJYiwSvV7PXXfdxaeffsq3337LDz/8QHZ2NgDOzs6MGjWK9957j99++40tW7aQkNB4J2vnkyt30TocW4v//s8Yr+vLj6E3m/8T+jMajYaYIA/0h9fQZeVHENwP7v/lz1cUwsa5ublx11138eyzz5Kfn8+9995rXhYWFsb333/P5s2b8fT0ZO7cuWRmZl72oFpDhgyhc+fOTJw4kbfeeov8/Hyee+45izphYWEkJyezaNEi+vTpw88//8ySJUss6rRr187cuVlQUBDu7u44Ojpa1JkwYQIvvPACEydOZNasWZw+fZpHH32Uu+++2/y8vTE8+eSTvPDCC3Ts2JHu3buzYMEC4uLi+OqrrwCYO3cuAQEB9OjRA61Wy3fffYe/vz8eHh4sXLiQqqoq+vXrh4uLC19++SXOzs4Wz+Ubm1y5i9ah+jW2HcZwel1mY7oa3YMN7FKdydd5gkcIXEb/CUJcDe6//35ycnKIjY21eD7+/PPP07NnT2JjY7nhhhvw9/dn9OjRl71drVbLkiVLKCkpoW/fvjzwwAO8+uqrFnVuvfVW/v73vzN16lS6d+/O5s2bmTFjhkWdO+64g2HDhnHjjTfi4+NT5+t4Li4urF69muzsbPr06cOdd955Qc+ljeGxxx5j+vTp/OMf/yAqKopVq1axbNkywsLCAFPL/zfffJPevXvTp08fTp48yYoVK9BqtXh4ePDpp58ycOBAoqOjWbt2LT/99FODulS/XBp1OT3FXGVSU1MJDg4mJSXlgk4ehBUYjag3QtGU5XNL2Su8+NDf6pXgfz96mrv/vY0QTxc2Pn1TEwYqrialpaUkJibSvn17nJycrB2OsBGX+r2qT26SK3fR8p0+iKYsnyLlyHFde7q1rd/IgNFBHoCG5JwSsosar0GQEEK0VJLcRctXPX77bmMYkW29cLSrX4t3g7M9HXxMjY7iU3Kg8HSjhyiEEC2JNKgTLV/N+O0NeN5eo3uQB+rMMfr+cA046OCJo3CZjfKEEKK1kSt30fLVNKZT4ZfdM935YoI9OKXa4FBRAEWnIftEY0YohBAtiiR30bLlpkB+KpVKyx5jpwZfuccEe1COPfvpYCpI2d6IQQohRMsiyV20bNVX7ftUO/y8vWjj5vgnK9Sta4A79joNWytNr62QIiPEicbRmL2cCdFYv0/yzF20bMnnPm+/9Pjtl+JopyMiQM/utJrkLlfu4so4ODig1WpJS0vDx8cHBweHy+5cSYjzKaUoLy/n9OnTaLVaHBwcrmh7ktxFy3ZO5zXXN/CWfI2YYA9+Tu1smsk6CCW54OxxZfGJq5ZWq6V9+/akp6eTltaAvuSFqIOLiwshISFotVd2Y12Su2i5SnJQWQfQALuM4fzjMgeLuZiYIA++wEC6LpCAqjRI3QlhQxonVnFVcnBwICQkhMrKyj/tA12IP6PT6bCzs2uUO0CS3EULpiGj3/Os27SZMidvOvm4XdHWakaI21rRiTHaNNNzd0nu4gppNBrs7e2bbHQvIRpCGtSJlsvZg9X6O3i+8n56hnii1V7Z2WyHNq64O9qxvar6uXuyNKoTQtgmSe6iRduZlANA7yt83g6g1WqIDjaw01g9DOSpXVBVecXbFUKIlsaqyX3jxo2MGjWKwMBANBoNS5cutViulGLmzJkEBATg7OzMkCFDOHr06J9u98MPP6Rdu3Y4OTnRr18/tm+XltGtTmUZxH1DxsmDgGrw++3niwny4JgKpFjrBhXFkNl04ykLIYS1WDW5FxUVERMTw4cffljn8jfffJP33nuPjz76iG3btuHq6kpsbCylpaUX3ea3337L9OnTeeGFF9i9ezcxMTHExsaSlZXVVF9DNIW0PbD0IeaXPYNOqzE/L79SMcEeKLTs01ZfvcsrcUIIG2TV5D58+HBeeeUVxowZc8EypRTz5s3j+eef57bbbiM6OpovvviCtLS0C67wzzV37lwmT57MfffdR0REBB999BEuLi58/vnnTfhNRKOrKifbqztbjJF0DdDj6tg4bT+7V58k/F5a3VPd2WONsl0hhGhJWuwz98TERDIyMhgypLY1s8FgoF+/fmzZsqXOdcrLy9m1a5fFOlqtliFDhlx0HYCysjLy8/PNU0FBQeN9EdEw7a/jvXb/4rGKqfS+gs5rzuend8Jf78RXlYPZPXYbjHir0bYthBAtRYtN7hkZGQD4+flZlPv5+ZmXne/MmTNUVVXVax2A2bNnYzAYzFNERMQVRn+epC2QvK1xt3kV2JWUA2gaPFjMxXQP9iAbPTvPyqtLQgjb1GKTe3N69tlnycvLM08HDhxotG2XpB2g8qtx8MWtcGhFo23XppUVUFyQw4H0fKBxWsqfq+b5fXxKXqNuVwghWooWm9z9/f0ByMzMtCjPzMw0LztfmzZt0Ol09VoHwNHREb1eb57c3d2vMHqT0ooqHl6WxcbSjlBZCt9OgJ0LGmXbNi3hO5znduAl7WcEGJwI9HBu1M3HBBsAcDz5K/x3DKx7qVG3L4QQ1tZik3v79u3x9/dn3bp15rL8/Hy2bdtG//7961zHwcGBXr16WaxjNBpZt27dRddpSnZaDR4eBiaXT2dx1Q2gjLB8Gvz2OijV7PG0Gslb0SgjpzE0+i15gKi2BjQaqCjKgeO/wrF1f76SEEK0IlbtfrawsJBjx2pbKycmJhIXF4eXlxchISFMmzaNV155hbCwMNq3b8+MGTMIDAxk9OjR5nUGDx7MmDFjmDp1KgDTp09n4sSJ9O7dm759+zJv3jyKioq47777mvvrYafT8va47tjptDy1azKZyoNH7ZbCb7MhPw1GzgWd9AB8gSRT48cdxnCGNEFyd3eyp5OPG1uyIjnccybhfYc2+j6EEMKarJpZdu7cyY033mienz59OgATJ05k4cKFPPXUUxQVFfHggw+Sm5vLoEGDWLVqFU5OTuZ1jh8/zpkzZ8zzd911F6dPn2bmzJlkZGTQvXt3Vq1adUEju+ai02p4845o7HVa3t4+jkzlycv2C9Hs/g8UnYY7/g0OLlaJrUXKS4W8ZCrREmfsxNNNkNzB9Nz9+6xCfnbqRbh/eJPsQwghrEWjlNwfPl9qairBwcGkpKQQFBTUKNtUSjFr2X7+syWJWO12/uX0L3TGcgjuB+MXgUvjve7VqiV8Dz/cz15je+5Sr7N31lDsdY3/9Oi/W5OYsXQf13X24YtJfRt9+0II0djqk5ta7DN3W6PRaJh1ayQPDGrPamNf/lLyDGV27pCyDT6Phdxka4fYMlQP5rLTGE5MsKFJEjtA9yAP0+6Sk1A7F8LmD5pkP0IIYQ2S3JuRRqPhuZFdefiGjuxQXbilaAaFjn5w5gj8eyhk7rd2iNZXndx3GMMbtfOa84X7u+Ngp8WtLAPN8sdh45tgNDbZ/oQQojlJcm9mGo2Gp2LDeXxwGEdVEDfnPc9Zlw5QkA47r/IuckvzIHMfADuNnRttsJi6ONhpiQzUc1CFUqlzNu37zOEm258QQjQnSe5WoNFo+PvNnXliaGfS8ebG7GfY1vZeVOxsa4dmXSnbAcVJox+n8aRHiEeT7i4myIMqdKQ4dzUVyPjuQggbIcndiqbeFMazw7uQjxt3HR/KG2tOoJQCYxUcWW3t8JpfsukVuJ0qnDBfNzxcHJp0dzWDyOwwdjYVyAhxQggbIcndyv7v+o7MvMXUl/1HG47z8k8HUCuegq/Hwfqr7Er+nOftTXlLvkZNN7S/FISaClLkyl0IYRskubcAkwa15+XR3QD4fHMi61K1KI0WfLtYObJmVFkGp3YBzZfc23m7oHeyY3tFR1NB9gkoPN3k+xVCiKYmyb2FuPuaUN64IwqNRsMDJ2/gnbD/YOw62tphNZ+ckyitHdnKnRMqoFmSu0ajISbYg3zcyHWrTvCpcmteCNH6SXJvQe7qE8LbY2PQauC9vTqe/H4vVUZl6rVt0QQoOvPnG2mtfMLZ89d4bi1/BS9XR9q3cW2W3dY8dz9kXz3MrzSqE0LYAOnYvIW5vWcQOq2G6Yvj+WF3KpVGI/NKnkOTtAmyDsDf/gde7a0dZpPYlZxPqvJhSIgnGo2mWfZZk9w3lnTgGpBGdUIImyBX7i3Qbd3b8sH4HthpNfwYl8ZLPIjyCDE9E/73UEiLs3aITWJXUg5As9ySrxFd3VPdyvwQU0HaHtPzfyGEaMUkubdQw6MCmP+3XtjrNCw4bM+T+jkY/bpBURYsHAnH11s7xMaTdQj1bncGn3gDgN7tmi+5+7g70tbDmUSjPxWOXlBVBunxzbZ/IYRoCpLcW7CbI/z45J7eONhp+f5IJY86vkJVu+ugvBC+Ggt7v7N2iI0jeQuanESCKlOw12mIamto1t2bbs1rSHWLro5HnrsLIVq3BiX3lJQUUlNTzfPbt29n2rRpfPLJJ40WmDC5MdyXzyf2wcley89Hinmg8ikqu44BYwX87wH4453W3yd6tzvYdM1HfFB1G93aGnCy1zXr7mOCTScTv+mugV73QmCPZt2/EEI0tgYl97/+9a+sX2+6LZyRkcHNN9/M9u3bee6553jppZcaNUABg8LasODevrg46Fh/LJ97ch+kos//mRaunQVfj4XCLKvGeEWc9Kwo6cYmYxS9QprvlnyNmOrn7p/k9YVR70L7a5s9BiGEaEwNSu779u2jb1/TGNiLFy+mW7dubN68ma+++oqFCxc2ZnyiWv+O3vxnUl/cHO3YnJjDhOTRlMbOATsnOLYW5g80/WylahrTNefz9hrd2hrQaiA9r5TM/NJm378QQjS2BiX3iooKHB0dAVi7di233norAF26dCE9Pb3xohMW+rTz4ov7++LuZMf2pBzG74mgcOIa8I0wNbT78g449LO1w6yfxI2UrZqJe9YOAHo2Y0v5Gq6OdnT2cwdgb1IWpO6ErEPNHocQQjSWBiX3yMhIPvroI37//XfWrFnDsGHDAEhLS8Pb27tRAxSWeoZ48vUD12BwtmdPci53/pDL8dHLoM9k8I+CTkOsHWL9HFyO49Z3GaHdRoiXC77uTlYJo+bWvH7zm/DZYNj2kVXiEEKIxtCg5P7GG2/w8ccfc8MNNzB+/HhiYmIAWLZsmfl2vWg6UUEGvpl8DW3cHDiUUcAt83ex2Pdx1KTVYGe6o0JVJRxeCUpZN9g/UzMSXDP1J38xNYPIbCrvAM5epscdQgjRSjWoh7obbriBM2fOkJ+fj6dn7X/IDz74IC4uLo0WnLi4iEA9Kx67lr8vjmPTsbM89cNeNh4N4LXbo9A72cPvc+C32dDrPhg1z9rh1q00HzL3AbDT2JmpVk3uphbz/znTlWkzj6PVyVuiQojWq0H/g5WUlFBWVmZO7ElJScybN4/Dhw/j6+vbqAGKi/PVO/HfSf14alg4Oq2G5XvTGfHu7+xOzgGdA2h0EDrA2mFeXOp2UEZSlC+ZeNHbism9s587TvZa8sqMnDhbbLU4hBCiMTQoud9222188cUXAOTm5tKvXz/efvttRo8ezfz58xs1wHbt2qHRaC6YpkyZUmf9hQsXXlDXycl2b7FqtRoeuaET3z3Un2AvZ1JzShj70RY+rLyVqke2Q/S42srZJ8BYZb1gz1fdWcx2Y2fcz2nUZg32Oi3dAk1X7/EpuabC8iKrxSOEEFeiQcl99+7dXHut6V3g77//Hj8/P5KSkvjiiy947733GjXAHTt2kJ6ebp7WrFkDwNixYy+6jl6vt1gnKSmpUWNqiXqGePLzY9cyKiaQKqPirdWHuXvpmdpXu4rOwOfD4IvbID/NusHWqE7uO43hdA/xQKdtnsFiLqbmuXvBgTUwNwK++YtV4xFCiIZqUHIvLi7G3d10lfXLL79w++23o9Vqueaaaxo9kfr4+ODv72+eli9fTseOHbn++usvuo5Go7FYx8/Pr1Fjaqn0Tva895fuvHVnNM72OjYfP8uweRtZdzATMvZCWSGc/N30TvyhFdYNtrLc9MoZsN3YxaqN6WrUJPddZ+0h/xSk7jI1TBRCiFamQcm9U6dOLF26lJSUFFavXs3QoUMByMrKQq/XN2qA5yovL+fLL79k0qRJlxwStLCwkNDQUIKDg7ntttvYv3//JbdbVlZGfn6+eSooKGjs0JuNRqNhbO9glj82iIgAPTnFFdz/n53M2u9H+QPrISAGSrJh0Xj4+QmoKLFOoBl7obKEXNw5rgLpHeplnTjO0aM6ua8+7YFy1ENFkbnBnxBCtCYNSu4zZ87kiSeeoF27dvTt25f+/fsDpqv4Hj2arl/upUuXkpuby7333nvROuHh4Xz++ef8+OOPfPnllxiNRgYMGGDRF/75Zs+ejcFgME8RERFNEH3z6ujjxpIpA5g00DT2+8LNJxm9KItjty6B/lNNlXZ8Cp8Otk6HLdWvwO2o6oxWozG3VremIE9nvFwdKK/SUOBT/Xucss26QQkhRANolGrYi9AZGRmkp6cTExODVms6R9i+fTt6vZ4uXbo0apA1YmNjcXBw4KeffrrsdSoqKujatSvjx4/n5ZdfrrNOWVkZZWW1Y3ifOnWKiIgIUlJSCAoKuuK4re3XQ5k88d1esovKcbbX8eKtkYz1OIRm6cNQdNr0Tnfsa9B7ElzijkijWjQBDi3ntYrx/O47gZWPt4z+3O9bsJ31h0+zJPIPehz/F3S7A+783NphCSEEqampBAcHX1ZuavDLvP7+/vTo0YO0tDTzVXHfvn2bLLEnJSWxdu1aHnjggXqtZ29vT48ePTh27NhF6zg6OqLX681TTXsCW3FTFz9WPX4tAzt5U1JRxVM/7OXRHd4UTNoAHQdDZSn8PB2+/RsUZzd9QEpZdF5jzVfgzlfz3H1LRZipIFmu3IUQrU+DkrvRaOSll17CYDAQGhpKaGgoHh4evPzyyxibaPjRBQsW4Ovry8iRI+u1XlVVFQkJCQQEBDRJXK1FXe/ED//sMLuv+xSGvgpaezi0HD4aBCc3NW0wZ49B8VnKcCBBdWgRjelq1CT35dkBpn4C8lMh7+KPdIQQoiVqUHJ/7rnn+OCDD3j99dfZs2cPe/bs4bXXXuP9999nxowZjR0jRqORBQsWMHHiROzsLDvVu+eee3j22WfN8y+99BK//PILJ06cYPfu3fztb38jKSmp3lf8tqjOd+I/3saHZcOomrQGvDqaWon/5xY4tavpAnHUU3HjCyyoGkYFdi0ruVf3MX/gjJEq30hToTx3F0K0Mg3qfvY///kPn332mXk0OIDo6Gjatm3LI488wquvvtpoAYJp5Lnk5GQmTZp0wbLk5GTzM3+AnJwcJk+eTEZGBp6envTq1YvNmzfbRCO5xlLzTvxzS/bxU3wab60+zKZj3sz76xp8/5gBJbkQ2LN2hV9fAZ8uED4CHBqhe2F3P3YHT+T1inB83R0J8nS+8m02Ei9XB0K8XEjOLibTozuBmXshZbvp2bsQQrQSDUru2dnZdT5b79KlC9nZjf/MdujQoVys3d9vv/1mMf/OO+/wzjvvNHoMtqbmnfjrwtrwwrL9bD5+lth/5TNn7AsMDvOsbVhXkAEb3wI08Mw5fRik7DAlep+uoK3/DaBdybXjt1/qtUZriAn2IDm7mARNOIFg7mxHCCFaiwbdlo+JieGDDz64oPyDDz4gOjr6ioMSzaPmnfifHh1EZOA578SvOEpZZXU3tcoI1zwCUXeC0zmvq/3yPMwfAG+2g6/Gwu9vQ9JmqCi99E6LsyHhe04cOwyY7iK0NDFBpu+5tqiDqSAjQbqiFUK0Kg26cn/zzTcZOXIka9euNb/jvmXLFlJSUlixwso9n4l66+jjxv8eGcCbqw7z7z8SWbj5JNsSs5l+c2eu6+yH47DZlisoZUr09q5QmgdHfzFNYBqwJrAHhFwDIf0huB+4nNNBTeJG+OF+JhPK98ymdzvrd15zvu7VjerWpzug9G3R5J8ytUFof511AxNCiMvUoOR+/fXXc+TIET788EMOHTJ1gHL77bfz4IMP8sorr5j7nReth6Odjhm3RDCoUxue+C6eg+n5TP5iJ3onO4Z18+fWmLb07+ht6v9do4EJi01ds2YmmG5bJ28x/SzMNDVAS9kGm941bbxNuCnZ93sItDpKfWLYlB6Ao52WiICm69GwoSIDDei0Gs4UllHaoTfO+adMV++S3IUQrUSDO7GpS3x8PD179qSqqgWNPNYA9ekowBZl5Zfy8cYTLN+bRmZ+bec+bdwcuSU6gFExAfQMqeNZuVKQc9Iy2Z85XLt80moIuYbFO1J46od4+rbzZvFD/ZvnS9XTiHd/50B6Pv+5zZvrI4LB0NbaIQkhrnL1yU0NunIXts1X78SMWyL454iubE/MZll8Giv3pXOmsIyFm0+ycPNJ2no4MyomkFExAUQE6E2JXqMBr/amqft408aKzpqu4pO3mG7XAzuTsgENvdq1vOftNWKCPTiQns/mXAPXS2IXQrQyktzFRem0Gvp39KZ/R29evDWSTcfOsCw+jV/2Z3Aqt4SPNhznow3H6ejjyq0xbbm1eyDt27habsTVG7qMME3VdiWZWsr3aoGN6Wp0DzbwzfZzxnbPTYHs4xA6EHT2prL8dCgvNM1r7U3tDXT21ZMDaO2arztfIYQ4hyR3cVkc7LTc2MWXG7v4UlJexa+HsvgpPo1fD2dx/HQR76w9wjtrj9CtrZ5bYwK5JTqQQI8L31/PKSrn+GlTy/OeLajzmvPV9FSXkJqHce93aOO+hBO/wbOptcl9/Suw58tLb0hrX5vwtfbQ4Qa489+1yz8fDsZKGLsADNW32Q78aNqXnTPYO4O9E9i7mMYAsK8uMy+rnpwM4BFSu12lLjyxKM42vdpYXmQa8a68+M8/u/rCiDdrt7FgBGQdgL9+B8F9TGUnNpiOg4u3qfGks+c5n71qP9u3nP4MhLB19Urut99++yWX5+bmXkksopVwdtAxMjqAkdEB5JdW8Mv+TH6KT+OPY2fYdyqffafyeW3FIfq282JUTAAjogLwdnMEYHf1++0dfFzxcnWw5te4pDBfd1wcdBSVV5FW7kJQWSH4RpiuyGvYOZmSalWFaTJWXLghY3V5zaKy84YTTttt6tv/3KYvKdthZz0HqwnsAQ/+Vjv/bjQUZML/bQDfrqaybR/Dhtfrt12vjpbzpXlQkgPl53yPzP2QsPjPt2XnXJ3oPcEjFP7yVe2yg8uhohjaDQJ9oKmsJBeKzoCdo2nSOVT/dGxQ3wpC/KmqSqgqh6qy6r/rcqis+XxemXfH2hPqgkw4utp0Eh51Z+32tn5kOkm+9h/N/lXqldwNhksPy2kwGLjnnnuuKCDRuuid7LmzVxB39gribGEZK/Zl8FNcGttPZpunWT8dYGCnNoyKDmDfqTyAFjVYTF10Wg1RbQ1sS8xmM9GMm7zuwkoj3zZNNZQyXYVXlVsm/HPnz796/ctXpr4BXH1qyzoNBkd3qCgxTZUltZ8rSkwnAxXFpvUqik3zLm0st1tRYvrPqLy4tszZ01TPwcX0GqOD659/dj1vu3d+bvqeHsG1ZaED4OaXofgslGSb7hAUZ9d+Lsk2HZfKElNf/fmpF57kbHwL0uPgr4trk/vBZbDs0br/gbT25yV8B9PJlrMH3P9Lbb3fXjedfPR7CNoNNJVln4BDP4Oj3nScnfS1n2t+OrjZ3glEVaWp3wq76hPUyjI4fQiMVaZ/U2UEVWX6aaz+aS5TtWWhA0zHGUzDRWckgGcoBPet3m45xH1Zmwgv+Fuo/hsxVtQuqyqH654A/yjTNg6tgD/egZB+MPSV2u/wbndTXaUAVRt3zecLyoBb5tYm3COrYfFEaNsL7vu5drvzokxjSKh6jI0SOxv6P2L6nJNo+l316mCZ3OO+NLU7aunJfcGCBU0Vh7AB3m6O3H1NKHdfE0pabgk/701nWXwaCafy2HjkNBuPnDbXbUn9yV9M92APtiVmE5+Sy7jewX++gkZTewv+cnUacmFZx5tM05V4ZKspwbv51pZd85BpuhI+4ReWBXY3TRejFJTlWyb881/SCe5nugtiOKcFsEZrSraVZaYTlXMZK6C8jjslTh6W8yf/gJO/Q8RttWUZ+0ydMF2SxjLZO7rDfStq/20TvoezxyHsZmhb3VVzYZap4ahGa5rQ1H7WaE2/H3XNB/Wp3W5OkukYuQeCu5+prDTfdOJTXlT9uKS49vP58+d+/uticKs+aVz9HGz5wJRkBs80leWnwccNeL1z8vra73x4Bax7EbpPqE3uVWWw/O/1326Pv9Um95JsSN1eexJRoyDddDJbH1Xn/J4Yq0wnmZUllnVqTlzOp3OsbUtj51j9911ddm5sLm2g83Bw97dcP/ouKCusX7yNRJ65iyYR6OHM5Os6MPm6Dpw4Xcjy6kR/LKsQB52WAR3b/PlGrKzmuXt8aq5V42iQ86+4rUmjMSVuJwPQvu465z7Xr9Hjb6YJTCcDNbdGK8tqE35luWUZ55009J9iSuzVb2oApv+Ao8aZTjjKCkw/S8/5bKw0bacs3zSB6U6B9pz/LvcvMY2i6OZTm+gy98HiBty5fDqpNlH8Pgd2fwE3zTBdyQKcPQr/GVX/7Zbl1yb3msdJ5/a0qLM3nURotKa7FOaTDl11me6ck5BzyuzPGV/CMxTaXw9tOp+zXQcIH1nbsFTnADq76kam9paNTs9tjHruNtpfB3d9Ce7njeY5aVX1h+q3cyx+auso01ie4Ha4Hh6PN93lOdfk9YCqjdfOsX4NYtt0gr8uurB8wEXuPDUDSe6iyXXwceOxwWE8elMnDmcWoEFDsFcjDEDTxGqS+6H0AkorqnCy11k3oKuZRmO6nWznYLqKvlzhwy8sC+5be5V5PqVMV4ZlBaapNM/0s6LE8j/6TkNMJ1C+5wxI5WiAkAHn3M42nnN7uGZeXbhce87vlZMH6Nua7hicW+bTxZRUHaofm1zs87nzbn612xj0d1OicXCrLTMEwT8OXv6xrEu3Oy4cVMnOEcZ/fWXb9QixbCBa49yTtIaoOUbnc/e7sKyVa9RObGzF1d6JjTBRStHn1XWcKSzjh4cHtIpHCUII21Wf3GRjLUaEaDwajYbuwaZGpOb33YUQohWQ5C7EJcQEeQAQJ8ldCNGKSHIX4hJadaM6IcRVS5K7EJcQXT22e9LZYnKKyq0cjRBCXB5J7kJcgoeLg7m//FdXHOSn+DQSzxRhNEo7VCFEyyWvwgnxJ67p4EXimSK+35XK97tSAXB3tCMiUE+3tga6tdXTLdBABx8303j3QghhZZLchfgTz42MoHuwBwmn8kg4lc/B9HwKyirZlpjNtsRscz1nex1dA9xNCT/QQGRbPWG+7jjYyQ0yIUTzatHJfdasWbz44osWZeHh4Rw6dOii63z33XfMmDGDkydPEhYWxhtvvMGIESMuWl+IP+PmaMddfUK4q3oQtIoqI8dPF1YPkpPH/rQ89qflU1xexe7kXHYn55rXddBpCfd3t7jCD/d3lw5xhBBNqkUnd4DIyEjWrl1rnrezu3jImzdvZvz48cyePZtbbrmFr7/+mtGjR7N79266devWHOGKq4C9TksXfz1d/PXc2cvUkUSVUXHybBH7TuVVT/nsS8ujoLSy+oo/z7y+TqshzNet+gpfT1SQB1FtDXKFL4RoNC26h7pZs2axdOlS4uLiLqv+XXfdRVFREcuXLzeXXXPNNXTv3p2PPvrosvcrPdSJxqCUIiW7hH1p1Qk/zXSln11Hq3tHOy0xQR70budJ73ae9ArxwuBSjwFohBA2rz65qcVfuR89epTAwECcnJzo378/s2fPJiSkjj6HgS1btjB9+nSLstjYWJYuXdoMkQphSaPREOLtQoi3CyOiTANgKKVIzyu1SPZ7knPIKa4wD5Fbo7OfG71CvejTzpPeoV4EezmjudyBLIQQV7UWndz79evHwoULCQ8PJz09nRdffJFrr72Wffv24e5+4eARGRkZ+PlZDgDg5+dHRkbGJfdTVlZGWVntkJIFBQWXqC1Ew2k0GgI9nAn0cGZopGl4SKUUJ84UsfNkNjtP5rAzKYfEM0UcySzkSGYh32xPBsDX3dF0VV+d8CMC9Njp5Fa+EOJCLTq5Dx9eO6JTdHQ0/fr1IzQ0lMWLF3P//fc32n5mz559QcM9IZqLRqOho48bHX3cuKuP6a7UmcIydp7MYVdSNjtO5rA/LY+sgjJWJGSwIsF0supsr6NHiAe9Qz3p3c6LHiEeuDvJrXwhRAtP7ufz8PCgc+fOHDt2rM7l/v7+ZGZmWpRlZmbi7+9/ye0+++yzFrfzT506RURExCXWEKJptXFzZFg3f4Z1M/3ullZUEZ+Sy86kHNMVflIOBaWVbD5+ls3HzwKg1UAXf3311b0p4QfondDKu/dCXHVaVXIvLCzk+PHj3H333XUu79+/P+vWrWPatGnmsjVr1tC/f/9LbtfR0RFHR0fzfH5+fqPEK0RjcbLX0a+DN/06eANgNCqOZhWy42Q2u5Jy2HEym9ScEg6k53MgPZ8vtiQBpoSvd7bH08UBg7M9Hi72eDjb43HOvKeLA4Zzyj2c7dE720uHPEK0Yi06uT/xxBOMGjWK0NBQ0tLSeOGFF9DpdIwfPx6Ae+65h7Zt2zJ79mwAHn/8ca6//nrefvttRo4cyaJFi9i5cyeffPKJNb+GEI1Oq9UQ7u9OuL87f7smFIDM/FJ2nswxJ/wD6flUGRW5xRXkFlfUex96Jzs8XU3J3lCd9GtODvwNzgzu6ouf3qmxv5oQohG06OSemprK+PHjOXv2LD4+PgwaNIitW7fi4+MDQHJyMlptbYOiAQMG8PXXX/P888/zz3/+k7CwMJYuXSrvuIurgp/eiZHRAYyMNrXML680kltSbk7uucXl5JZUkFdcUVt+znxOUQV5JRUUllUCkF9aSX5pJUkX2Z9mKfRp58Wo6ACGdQvAx93xIjWFEM2tRb/nbi3ynru4mlVUGckrMZ0Q5J17clBSQV5xOTnFFexPy7PoiU+rgWs6eDMyOoDh3QLwcnWw3hcQwkbZ1HvuQojmZa/T0sbNkTZul74SP5Vbwoq96SxPSCc+JdfcuG/mj/sZ0NGbW6IDiI30x8NFEr0QzU2u3OsgV+5C1E9KdjHL96bzc0Ia+07VNki102q4NqwNI6MDGRrph15e1ROiweqTmyS510GSuxANl3imiJ/3prF8bzqHMmo7hHLQabmucxtuiQ5kcFdfeSdfiHqS5H6FJLkL0TiOZRXy8950lu9N42hWobncwU7LjeE+5kTv4iBPCIX4M5Lcr5AkdyEa3+GMApZXX9EnnikylzvZaxncxY9bogO4IdwXZwcZDleIukiDOiFEi2N6Lz+c6Td35kB6fvUVfTrJ2cX8nJDOzwnpuDjouL6zD9d19mFQpzYEe7lYO2whWiVJ7kKIZqXRaIgMNBAZaODJ2HASTuWZE/2p3BJW7stg5T5T//nt27hybVgbrg3z4ZoOXvKcXojLJLfl6yC35YVofkop4lPz2HD4NL8fPc2elFyqjLX/PdlpNfQM8TQl+84+RLU1SBe54qoiz9yvkCR3Iawvv7SCLcfP8vvR0/x+9AxJZ4stlhuc7RnYyZtrw3y4NqwNQZ5yC1/YNnnmLoRo9fRO9sRG+hNbPe598tlifj92mt+PnGHT8TPklVRYDIHb4dxb+B29cXOU/97E1Ut++4UQrUKItwsTvEOZ0C+Uyioj8al5/HH0jPkW/okzRZw4U8R/tiTJLXxx1ZPb8nWQ2/JCtC6Xewu/Z4gnUW0NRLY1yJW9aHXktrwQ4qpS31v4Go3pNn50kAdRbQ1EBxmICNRLZzrCZshvshDC5tR1C3/ribPsTc0lITWPtLxSjp8u4vjpIpbsOQWYRrbr5OtGVFsPotrqiQryICJAL53qiFZJkrsQwqbZ6bT0CvWkV6inuex0QRn7TuWRcCqPval5JJzKJTO/jCOZhRzJLOSH3aZ6Oq2GMF8389V9VJAHXfzdcbKXhC9aNknuQoirjo+7Izd28eXGLr7msqz80nOSfR57U3M5U1jOoYwCDmUU8N2uVMD0vn1nP/fqZG8guq0H4f7uONhprfV1hLiAJHchhAB89U4M1jsxuKsfYOpUJyO/lITUPIukn11UzoH0fA6k57NoRwoAbo52jIoJYGzvYHoEe6DRSMt8YV2S3IUQog4ajYYAgzMBBmeGVjfUU0pxKreEfRZX+HnklVTwzfYUvtmeQkcfV8b1DmZMz7b4ujtZ+VuIq5W8ClcHeRVOCHG5jEbF9pPZLN6ZwoqEdEorjIDpef2N4b6M7R3ETV18sdfJbXtxZaT72SskyV0I0RAFpRUs35vOdztT2J2cay5v4+bAmB5tGds7mM5+7tYLULRqktyvkCR3IcSVOpZVwHc7U/lh9ynOFJaZy2OCPRjXO4hRMYHoZZQ7UQ/1yU0t+j7R7Nmz6dOnD+7u7vj6+jJ69GgOHz58yXUWLlyIRqOxmJyc5LmXEKJ5dfJ159kRXdny7E18dk9vhkb4YafVEJ+Sy3NL9tHnlbVMW7SHzcfOYDTKNZZoXC26Qd2GDRuYMmUKffr0obKykn/+858MHTqUAwcO4OrqetH19Hq9xUmAtFwVQliLvU7LkAg/hkT4cbqgjKV7TrF4ZwpHswpZGpfG0rg0gjydubNXEHf2CpLR7USjaFW35U+fPo2vry8bNmzguuuuq7POwoULmTZtGrm5uQ3ej9yWF0I0pZqx6xfvTOGnuDQKyioBU7e4Azu2YWzvIGIj/aWzHGHBZvuWz8vLA8DLy+uS9QoLCwkNDcVoNNKzZ09ee+01IiMjmyNEIYT4UxqNhu7BHnQP9mDGyAhW789g8c4UNh8/yx/HzvDHsTO4O9lxW/dABnVqQ7s2roR4uUjf9+KytZord6PRyK233kpubi5//PHHRett2bKFo0ePEh0dTV5eHnPmzGHjxo3s37//omc6ZWVllJXVNng5deoUERERcuUuhGhWKdnFfL8rle93pXIqt+SC5b7ujrTzdiXU24V2bap/Vs+7S+M8m2eTreUffvhhVq5cyR9//FGvhFtRUUHXrl0ZP348L7/8cp11Zs2axYsvvnhBuSR3IYQ1GI2KzcfP8mPcKY5kFZJ0tojc4opLruPt6nBOsnelXRsX009vFzxcHJopctGUbC65T506lR9//JGNGzfSvn37eq8/duxY7Ozs+Oabb+pcLlfuQoiWLre4nKSzxZw8W2TxM+lsEWcKyy+5rsHZnnbetck+xNuV9m1cCPfXy7j2rYjNPHNXSvHoo4+yZMkSfvvttwYl9qqqKhISEhgxYsRF6zg6OuLo6Giez8/Pb1C8QgjRVDxcHPBwcSAm2OOCZQWlFdWJvibpF3GyOvFn5peRV1JBfGoe8al5F6wb6u1CRIDeNAWaJn+9k7xl1Mq16OQ+ZcoUvv76a3788Ufc3d3JyMgAwGAw4OzsDMA999xD27ZtmT17NgAvvfQS11xzDZ06dSI3N5e33nqLpKQkHnjgAat9DyGEaEruTvZ0a2ugW1vDBcuKyytJzi7m5Jlii6R//HQhmfll5pOClfsyzOt4uNhfkPA7+rhJF7qtSItO7vPnzwfghhtusChfsGAB9957LwDJyclotbW/cDk5OUyePJmMjAw8PT3p1asXmzdvJiIiornCFkKIFsPFwY4u/nq6+OsvWHa2sIyD6QUcrB7l7kBaPsdOF5JbXMHm42fZfPysua6DTkuYn1ttwg/Q0yVAj8FZGvK1RK3imXtzk/fchRBXq9KKKo5mFlok/IPp+eZ38c8X5OlskfC7BugJ8nSW2/pNwGaeuQshhGheTvY6ooIMRAXV3uJXSpGaU8L+NMuEfyq3hNQc0/TLgUxzfb2TnfkxQbe2BroF6mnn7YpWKwm/uUhyF0IIcUkajYZgLxeCvVwY1s3fXJ5bXM7B9AJzwj+Qns+xrALySysvuK3v5mhHRKCeqLYGurXV0y3QQAcfN3SS8JuEJHchhBAN4uHiQP+O3vTv6G0uK680ciSzgP1peSScymPfKdNVfmFZJdsTs9memG2u62yvMyf8yEA93doaCPN1w04a7l0xSe5CCCEajYOd1nw7/q4+prLKKiPHThey71Q++07lse9UHvvT8impqGJXUg67knLM6zvaaekSoKeb+SrfQGc/dxzsJOHXhyR3IYQQTcpOpzW32L+zl6khWJVRkXjGlPATzkn4hWWVxKfkEp+Sa17fXqch3N+dboEGIgJN2wn3d5eW+pcgyV0IIUSz02k1dPJ1p5OvO6N7tAVM3e4mZRebru7T8qqv8vPJK6movuq37GCsrYczXQPcTScO1T/bt3GV5/hIchdCCNFCaLUa2rdxpX0bV0bFBAK1LfVrEv6h9AIOZRRwKrfEPK09mGXehqOdls5+7hZJv6u/Hk/Xq6t/fUnuQgghWqxzW+oPjwowl+cVV3AoI59DGQUcysjnYHoBhzMKKKmoIuGUqTHfufz0jhbJvmuAng4+rjbb654kdyGEEK2OwcWefh286dehtqW+0ahIzi7mYHo+BzMKOJRuSv7J2cVk5peRmX+aDUdOm+vb60yPBrr6u9M1QE9UkKkBny0MptP6v4EQQgiB6bZ+uzautGvjanGVX1hWyWHzFX6++dZ+YVml6UQgPR/2nAJAo4FOPm5EB3kQE2wgOsiDrgHuONrprPW1GkSSuxBCCJvm5mhHr1BPeoV6mstqnuUfqr7C35eWx97UPNLzSjmaVcjRrEJ+2J0KmK7wu/jriQ4yEBPkQXSwgU4+Lft9fEnuQgghrjrnPsu/OcLPXJ5VUMrelDz2puYSn2r6mVNcYX6O/9W2ZMDUAU9koN7iCr+dt0uL6VNfkrsQQghRzdfdiSERTgypTvg1V/jxqbnsTc0jPiWXfafyKCqvYmdSDjvP6YBH72RHdJAH0UEGc9L31ztZJeFLchdCCCEu4twr/FuiTa/nVRkVJ04Xmq/s41PzOJiWT35pJX8cO8Mfx86Y1/dxdyQmyMD743vi7NB8z+0luQshhBD1oNNqCPNzJ8zP3dzjXk2f+vGpuexNySM+NZcjmQWcLigjLiUPJ/vmfT4vyV0IIYS4Quf2qT+hn6mspLyK/Wl5nC0qb/Zb85LchRBCiCbg7KCjdzsvq+y75bbjF0IIIUSDSHIXQgghbIwkdyGEEMLGSHIXQgghbIwkdyGEEMLGSGv5OhiNRgDS09OtHIkQQghhUpOTanLUpUhyr0NmZiYAffv2tXIkQgghhKXMzExCQkIuWUejlFLNFE+rUVlZyZ49e/Dz80OrvbInFwUFBURERHDgwAHc3d0bKULbJses/uSY1Z8cs/qTY1Z/jXnMjEYjmZmZ9OjRAzu7S1+bS3JvYvn5+RgMBvLy8tDr9dYOp1WQY1Z/cszqT45Z/ckxqz9rHTNpUCeEEELYGEnuQgghhI2R5N7EHB0deeGFF3B0dLR2KK2GHLP6k2NWf3LM6k+OWf1Z65jJM3chhBDCxsiVuxBCCGFjJLkLIYQQNkaSuxBCCGFjJLk3sQ8//JB27drh5OREv3792L59u7VDarFmz55Nnz59cHd3x9fXl9GjR3P48GFrh9VqvP7662g0GqZNm2btUFq8U6dO8be//Q1vb2+cnZ2Jiopi586d1g6rxaqqqmLGjBm0b98eZ2dnOnbsyMsvv4w02aq1ceNGRo0aRWBgIBqNhqVLl1osV0oxc+ZMAgICcHZ2ZsiQIRw9erTJ4pHk3oS+/fZbpk+fzgsvvMDu3buJiYkhNjaWrKwsa4fWIm3YsIEpU6awdetW1qxZQ0VFBUOHDqWoqMjaobV4O3bs4OOPPyY6OtraobR4OTk5DBw4EHt7e1auXMmBAwd4++238fT0tHZoLdYbb7zB/Pnz+eCDDzh48CBvvPEGb775Ju+//761Q2sxioqKiImJ4cMPP6xz+Ztvvsl7773HRx99xLZt23B1dSU2NpbS0tKmCUiJJtO3b181ZcoU83xVVZUKDAxUs2fPtmJUrUdWVpYC1IYNG6wdSotWUFCgwsLC1Jo1a9T111+vHn/8cWuH1KI9/fTTatCgQdYOo1UZOXKkmjRpkkXZ7bffriZMmGCliFo2QC1ZssQ8bzQalb+/v3rrrbfMZbm5ucrR0VF98803TRKDXLk3kfLycnbt2sWQIUPMZVqtliFDhrBlyxYrRtZ65OXlAeDl5WXlSFq2KVOmMHLkSIvfNXFxy5Yto3fv3owdOxZfX1969OjBp59+au2wWrQBAwawbt06jhw5AkB8fDx//PEHw4cPt3JkrUNiYiIZGRkWf6MGg4F+/fo1WT6QUeGayJkzZ6iqqsLPz8+i3M/Pj0OHDlkpqtbDaDQybdo0Bg4cSLdu3awdTou1aNEidu/ezY4dO6wdSqtx4sQJ5s+fz/Tp0/nnP//Jjh07eOyxx3BwcGDixInWDq9FeuaZZ8jPz6dLly7odDqqqqp49dVXmTBhgrVDaxUyMjIA6swHNcsamyR30SJNmTKFffv28ccff1g7lBYrJSWFxx9/nDVr1uDk5GTtcFoNo9FI7969ee211wDo0aMH+/bt46OPPpLkfhGLFy/mq6++4uuvvyYyMpK4uDimTZtGYGCgHLMWSm7LN5E2bdqg0+nMY8PXyMzMxN/f30pRtQ5Tp05l+fLlrF+/nqCgIGuH02Lt2rWLrKwsevbsiZ2dHXZ2dmzYsIH33nsPOzs7qqqqrB1iixQQEEBERIRFWdeuXUlOTrZSRC3fk08+yTPPPMNf/vIXoqKiuPvuu/n73//O7NmzrR1aq1Dzf35z5gNJ7k3EwcGBXr16sW7dOnOZ0Whk3bp19O/f34qRtVxKKaZOncqSJUv49ddfad++vbVDatEGDx5MQkICcXFx5ql3795MmDCBuLg4dDqdtUNskQYOHHjBK5ZHjhwhNDTUShG1fMXFxWi1lulCp9NhNBqtFFHr0r59e/z9/S3yQX5+Ptu2bWuyfCC35ZvQ9OnTmThxIr1796Zv377MmzePoqIi7rvvPmuH1iJNmTKFr7/+mh9//BF3d3fzsyiDwYCzs7OVo2t53N3dL2iP4Orqire3t7RTuIS///3vDBgwgNdee41x48axfft2PvnkEz755BNrh9ZijRo1ildffZWQkBAiIyPZs2cPc+fOZdKkSdYOrcUoLCzk2LFj5vnExETi4uLw8vIiJCSEadOm8corrxAWFkb79u2ZMWMGgYGBjB49umkCapI2+MLs/fffVyEhIcrBwUH17dtXbd261dohtVhAndOCBQusHVqrIa/CXZ6ffvpJdevWTTk6OqouXbqoTz75xNohtWj5+fnq8ccfVyEhIcrJyUl16NBBPffcc6qsrMzaobUY69evr/P/r4kTJyqlTK/DzZgxQ/n5+SlHR0c1ePBgdfjw4SaLR0aFE0IIIWyMPHMXQgghbIwkdyGEEMLGSHIXQgghbIwkdyGEEMLGSHIXQgghbIwkdyGEEMLGSHIXQgghbIwkdyGEEMLGSHIXQrQIGo2GpUuXWjsMIWyCJHchBPfeey8ajeaCadiwYdYOTQjRADJwjBACgGHDhrFgwQKLMkdHRytFI4S4EnLlLoQATInc39/fYvL09ARMt8znz5/P8OHDcXZ2pkOHDnz//fcW6yckJHDTTTfh7OyMt7c3Dz74IIWFhRZ1Pv/8cyIjI3F0dCQgIICpU6daLD9z5gxjxozBxcWFsLAwli1bZl6Wk5PDhAkT8PHxwdnZmbCwsAtORoQQJpLchRCXZcaMGdxxxx3Ex8czYcIE/vKXv3Dw4EEAioqKiI2NxdPTkx07dvDdd9+xdu1ai+Q9f/58pkyZwoMPPkhCQgLLli2jU6dOFvt48cUXGTduHHv37mXEiBFMmDCB7Oxs8/4PHDjAypUrOXjwIPPnz6dNmzbNdwCEaE2abLw5IUSrMXHiRKXT6ZSrq6vF9OqrryqlTMPxPvTQQxbr9OvXTz388MNKKaU++eQT5enpqQoLC83Lf/75Z6XValVGRoZSSqnAwED13HPPXTQGQD3//PPm+cLCQgWolStXKqWUGjVqlLrvvvsa5wsLYePkmbsQAoAbb7yR+fPnW5R5eXmZP/fv399iWf/+/YmLiwPg4MGDxMTE4Orqal4+cOBAjEYjhw8fRqPRkJaWxuDBgy8ZQ3R0tPmzq6srer2erKwsAB5++GHuuOMOdu/ezdChQxk9ejQDBgxo0HcVwtZJchdCAKZkev5t8sbi7Ox8WfXs7e0t5jUaDUajEYDhw4eTlJTEihUrWLNmDYMHD2bKlCnMmTOn0eMVorWTZ+5CiMuydevWC+a7du0KQNeuXYmPj6eoqMi8fNOmTWi1WsLDw3F3d6ddu3asW7fuimLw8fFh4sSJfPnll8ybN49PPvnkirYnhK2SK3chBABlZWVkZGRYlNnZ2ZkbrX333Xf07t2bQYMG8dVXX7F9+3b+/e9/AzBhwgReeOEFJk6cyKxZszh9+jSPPvood999N35+fgDMmjWLhx56CF9fX4YPH05BQQGbNm3i0Ucfvaz4Zs6cSa9evYiMjKSsrIzly5ebTy6EEJYkuQshAFi1ahUBAQEWZeHh4Rw6dAgwtWRftGgRjzzyCAEBAXzzzTdEREQA4OLiwurVq3n88cfp06cPLi4u3HHHHcydO9e8rYkTJ1JaWso777zDE088QZs2bbjzzjsvOz4HBweeffZZTp48ibOzM9deey2LFi1qhG8uhO3RKKWUtYMQQrRsGo2GJUuWMHr0aGuHIoS4DPLMXQghhLAxktyFEEIIGyPP3IUQf0qe3gnRusiVuxBCCGFjJLkLIYQQNkaSuxBCCGFjJLkLIYQQNkaSuxBCCGFjJLkLIYQQNkaSuxBCCGFjJLkLIYQQNkaSuxBCCGFj/h91nhCHsOYjqwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses,         val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the picture for nothing--I told Mrs.\n",
      "\"Oh, my work, and went on grop\n"
     ]
    }
   ],
   "source": [
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperatue scaling\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "    temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to happen a little wild--I was such a laugh; and\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = GPTModel(GPT_CONFIG_124M)\n",
    "model2.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow>2.15.0 tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 15.6kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 650kiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 12.5kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [03:24<00:00, 2.43MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 281kiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 447kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 402kiB/s] \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size = \"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "            \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
